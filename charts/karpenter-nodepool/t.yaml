# Global settings
nameOverride: "staging"

globalLabels:
  environment: staging
  managed-by: karpenter
  cluster: staging-cluster

globalAnnotations: {}

# NodePool Configuration
nodePool:
  staging:
    # Labels applied to all nodes (cannot use kubernetes.io domain - it's restricted)
    # Note: environment, managed-by, cluster labels come from globalLabels
    labels:
      nodepool: staging
      workload-type: general
      cost-optimization: enabled
    
    # Annotations applied to all nodes
    # annotations:
    #   cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      
    # Reference to EC2NodeClass
    nodeClassRef:
      group: karpenter.k8s.aws
      kind: EC2NodeClass
      name: staging
    
    # Taints for specialized workloads
    taints: []
    
    # Startup taints (temporary)
    # startupTaints:
    #   - key: node.kubernetes.io/not-ready
    #     effect: NoSchedule
    
    # Termination grace period - maximum time for node draining before forceful termination
    # In v1.5: Enables drift disruption even with blocking PDBs or do-not-disrupt annotations
    # Combined with expireAfter (720h), maximum node lifetime = 720h + 5m
    terminationGracePeriod: 5m
    
    # Instance requirements
    requirements:
      - key: "karpenter.k8s.aws/instance-category"
        operator: In
        values: ["c", "m", "r", "t"]
      - key: "karpenter.k8s.aws/instance-cpu"
        operator: In
        values: ["2", "4", "8", "16", "32"]
      - key: "karpenter.k8s.aws/instance-hypervisor"
        operator: In
        values: ["nitro"]
      - key: "karpenter.k8s.aws/instance-generation"
        operator: Gt
        values: ["2"]
      - key: "kubernetes.io/arch"
        operator: In
        values: ["amd64"]
      - key: "karpenter.sh/capacity-type"
        operator: In
        values: ["spot", "on-demand"]
      - key: "node.kubernetes.io/instance-type"
        operator: NotIn
        values: ["nano", "micro", "small"]
    
    # Node expiration (30 days for staging)
    expireAfter: 720h
    
    # NOTE: In Karpenter v1.5, kubelet configuration MOVED to EC2NodeClass spec
    # See EC2NodeClass section below for kubelet configuration
    
    # Disruption settings (Karpenter v1.5 compliant)
    disruption:
      consolidationPolicy: WhenEmptyOrUnderutilized
      consolidateAfter: 30s  # Wait 30s after pod changes before considering consolidation
      
      # Disruption budgets to rate-limit voluntary disruptions
      budgets:
        - nodes: "20%"          # Allow up to 20% of nodes to be disrupted
          reasons: ["Empty", "Underutilized"]
        - nodes: "3"            # But never more than 3 nodes at once
        - nodes: "0"            # Block all disruptions during business hours
          schedule: "0 8 * * 1-5"  # 8 AM Mon-Fri UTC  
          duration: "10h"       # For 10 hours (8 AM - 6 PM)
          reasons: ["Underutilized"]
    
    # Resource limits for the entire nodepool
    limits:
      cpu: 1000
      memory: 1000Gi
    
    # Priority weight for this nodepool
    weight: 10

# EC2NodeClass Configuration  
ec2NodeClass:
  staging:
    # AMI Family
    amiFamily: AL2
    
    # Subnet selection for staging environment
    subnetSelectorTerms:
      - tags:
          karpenter.sh/discovery: "staging-cluster"
          kubernetes.io/role/internal-elb: "1"
      - tags:
          Name: "staging-private-*"
          Environment: "staging"
    
    # Security group selection
    securityGroupSelectorTerms:
      - tags:
          karpenter.sh/discovery: "staging-cluster"
      - tags:
          Name: "staging-worker-*"
          Environment: "staging"
    
    # IAM role for nodes
    role: "KarpenterNodeInstanceProfile-staging"
    
    # Instance profile (alternative to role)
    instanceProfile: ""
    
    # AMI selection (alias is mutually exclusive with other terms)
    amiSelectorTerms:
      - alias: al2@latest
    
    # Custom user data
    userData: |-
      #!/bin/bash
      /etc/eks/bootstrap.sh staging-cluster
      yum update -y
      echo "Node initialization completed"
    
    # Capacity reservations
    capacityReservationSelectorTerms: []
    
    # Tags to apply to EC2 instances
    tags:
      Environment: staging
      Project: opswat
      ManagedBy: karpenter
      NodePool: staging
      Cluster: staging-cluster
      AutoScaling: enabled
      Purpose: worker-nodes
    
    # Instance metadata options (v1.5 security best practices)
    metadataOptions:
      httpEndpoint: enabled
      httpProtocolIPv6: disabled
      httpPutResponseHopLimit: 1  # v1.5 recommended: disable IMDS access from containers not on host network
      httpTokens: required
    
    # Block device mappings
    blockDeviceMappings:
      - deviceName: /dev/xvda
        ebs:
          volumeSize: 100Gi
          volumeType: gp3
          iops: 3000
          encrypted: true
          deleteOnTermination: true
          throughput: 125
    
    # Instance store policy
    instanceStorePolicy: RAID0
    
    # Detailed monitoring
    detailedMonitoring: true
    
    # Public IP association
    associatePublicIPAddress: false
    
    # Kubelet configuration (v1.5 location - moved from NodePool to EC2NodeClass)
    kubelet:
      clusterDNS: ["172.20.0.10"]
      # Note: containerRuntime is automatically determined by AMI family in v1.5.x
      systemReserved:
        cpu: 100m
        memory: 100Mi
        ephemeral-storage: 1Gi
      kubeReserved:
        cpu: 200m
        memory: 100Mi
        ephemeral-storage: 3Gi
      evictionHard:
        memory.available: 5%
        nodefs.available: 10%
        nodefs.inodesFree: 10%
      evictionSoft:
        memory.available: 500Mi
        nodefs.available: 15%
        nodefs.inodesFree: 15%
      evictionSoftGracePeriod:
        memory.available: 1m
        nodefs.available: 1m30s
        nodefs.inodesFree: 2m
      evictionMaxPodGracePeriod: 60
      imageGCHighThresholdPercent: 85
      imageGCLowThresholdPercent: 80
      cpuCFSQuota: true
      maxPods: 110
